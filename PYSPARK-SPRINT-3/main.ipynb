{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "from processing import Process\n",
    "\n",
    "conf = SparkConf()\n",
    "# conf.set('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.2.0')\n",
    "# conf.set('spark.hadoop.fs.s3a.aws.credentials.provider', 'com.amazonaws.auth.InstanceProfileCredentialsProvider')\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "procdata = Process()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONVERT FILES FROM CSV TO JSON AND XML\n",
    "\n",
    "geralprounicsv = pd.read_csv(\"pure_data/GERAL-cursos-prouni.csv\")\n",
    "addprounicsv = pd.read_csv(\"pure_data/pda-prouni.csv\", sep=';')\n",
    "\n",
    "geralprounicsv.to_xml(\"pure_data/geralprouni.xml\")\n",
    "addprounicsv.to_json(\"pure_data/prouni.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41447 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": "       mensalidade estado                          curso  quantidade_bolsas  \\\n38393       237.00     PR                       História                2.0   \n2335       1440.86     RO               Engenharia Civil               14.0   \n31550       278.00     RR        Relações Internacionais                1.0   \n23507       327.14     SP                Letras - Inglês                1.0   \n22114       347.49     PR                      Pedagogia                1.0   \n41232       149.00     MG               Gestão Comercial                1.0   \n32123       277.00     RS                 Serviço Social                1.0   \n35767       257.19     SP  Letras - Português e Espanhol                1.0   \n31947       278.00     SP               Gestão Ambiental                1.0   \n27911       298.00     MG             Ciências Contábeis                1.0   \n\n       nota_bolsa  \n38393     558.990  \n2335      610.935  \n31550     518.540  \n23507     530.340  \n22114     496.020  \n41232     571.200  \n32123     577.680  \n35767     546.480  \n31947     450.000  \n27911     555.740  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mensalidade</th>\n      <th>estado</th>\n      <th>curso</th>\n      <th>quantidade_bolsas</th>\n      <th>nota_bolsa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38393</th>\n      <td>237.00</td>\n      <td>PR</td>\n      <td>História</td>\n      <td>2.0</td>\n      <td>558.990</td>\n    </tr>\n    <tr>\n      <th>2335</th>\n      <td>1440.86</td>\n      <td>RO</td>\n      <td>Engenharia Civil</td>\n      <td>14.0</td>\n      <td>610.935</td>\n    </tr>\n    <tr>\n      <th>31550</th>\n      <td>278.00</td>\n      <td>RR</td>\n      <td>Relações Internacionais</td>\n      <td>1.0</td>\n      <td>518.540</td>\n    </tr>\n    <tr>\n      <th>23507</th>\n      <td>327.14</td>\n      <td>SP</td>\n      <td>Letras - Inglês</td>\n      <td>1.0</td>\n      <td>530.340</td>\n    </tr>\n    <tr>\n      <th>22114</th>\n      <td>347.49</td>\n      <td>PR</td>\n      <td>Pedagogia</td>\n      <td>1.0</td>\n      <td>496.020</td>\n    </tr>\n    <tr>\n      <th>41232</th>\n      <td>149.00</td>\n      <td>MG</td>\n      <td>Gestão Comercial</td>\n      <td>1.0</td>\n      <td>571.200</td>\n    </tr>\n    <tr>\n      <th>32123</th>\n      <td>277.00</td>\n      <td>RS</td>\n      <td>Serviço Social</td>\n      <td>1.0</td>\n      <td>577.680</td>\n    </tr>\n    <tr>\n      <th>35767</th>\n      <td>257.19</td>\n      <td>SP</td>\n      <td>Letras - Português e Espanhol</td>\n      <td>1.0</td>\n      <td>546.480</td>\n    </tr>\n    <tr>\n      <th>31947</th>\n      <td>278.00</td>\n      <td>SP</td>\n      <td>Gestão Ambiental</td>\n      <td>1.0</td>\n      <td>450.000</td>\n    </tr>\n    <tr>\n      <th>27911</th>\n      <td>298.00</td>\n      <td>MG</td>\n      <td>Ciências Contábeis</td>\n      <td>1.0</td>\n      <td>555.740</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geralprouni = pd.DataFrame(pd.read_xml(\"pure_data/geralprouni.xml\"))\n",
    "\n",
    "quantidade_bolsas = geralprouni[['bolsa_integral_cotas', 'bolsa_integral_ampla', 'bolsa_parcial_cotas', 'bolsa_parcial_ampla']].sum(axis=1)\n",
    "nota_bolsa = geralprouni[['nota_integral_ampla', 'nota_integral_cotas', 'nota_parcial_ampla', 'nota_parcial_cotas']].mean(axis=1)\n",
    "\n",
    "prouni = pd.DataFrame({\n",
    "    'mensalidade': geralprouni['mensalidade'], \n",
    "    'estado': geralprouni['uf_busca'], \n",
    "    'curso': geralprouni['nome'], \n",
    "    'quantidade_bolsas': quantidade_bolsas,\n",
    "    'nota_bolsa': nota_bolsa\n",
    "})\n",
    "#geralprouni.head(5)\n",
    "print(prouni.__len__(), \"rows\")\n",
    "prouni.sample(n=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236636 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                              curso estado       sexo    raca  \\\n219829                                    Pedagogia     MA   Feminino   Parda   \n233459                       Engenharia De Produção     MA  Masculino   Parda   \n200465                                   Enfermagem     MA  Masculino  Branca   \n219591                                   Enfermagem     MA   Feminino  Branca   \n180904  Curso Superior De Tecnologia Em Gastronomia     GO   Feminino  Branca   \n219962                           Ciências Contábeis     AC   Feminino   Parda   \n187436                                    Pedagogia     MS   Feminino  Branca   \n113714                       Engenharia De Produção     RS  Masculino  Branca   \n188936                                    Pedagogia     RJ   Feminino   Parda   \n154159                         Medicina Veterinária     SP   Feminino   Outro   \n\n       deficiente  idade  \n219829        Não     25  \n233459        Não     24  \n200465        Não     23  \n219591        Não     35  \n180904        Não     24  \n219962        Não     30  \n187436        Não     23  \n113714        Não     44  \n188936        Não     23  \n154159        Não     26  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>curso</th>\n      <th>estado</th>\n      <th>sexo</th>\n      <th>raca</th>\n      <th>deficiente</th>\n      <th>idade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>219829</th>\n      <td>Pedagogia</td>\n      <td>MA</td>\n      <td>Feminino</td>\n      <td>Parda</td>\n      <td>Não</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>233459</th>\n      <td>Engenharia De Produção</td>\n      <td>MA</td>\n      <td>Masculino</td>\n      <td>Parda</td>\n      <td>Não</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>200465</th>\n      <td>Enfermagem</td>\n      <td>MA</td>\n      <td>Masculino</td>\n      <td>Branca</td>\n      <td>Não</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>219591</th>\n      <td>Enfermagem</td>\n      <td>MA</td>\n      <td>Feminino</td>\n      <td>Branca</td>\n      <td>Não</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>180904</th>\n      <td>Curso Superior De Tecnologia Em Gastronomia</td>\n      <td>GO</td>\n      <td>Feminino</td>\n      <td>Branca</td>\n      <td>Não</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>219962</th>\n      <td>Ciências Contábeis</td>\n      <td>AC</td>\n      <td>Feminino</td>\n      <td>Parda</td>\n      <td>Não</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>187436</th>\n      <td>Pedagogia</td>\n      <td>MS</td>\n      <td>Feminino</td>\n      <td>Branca</td>\n      <td>Não</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>113714</th>\n      <td>Engenharia De Produção</td>\n      <td>RS</td>\n      <td>Masculino</td>\n      <td>Branca</td>\n      <td>Não</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>188936</th>\n      <td>Pedagogia</td>\n      <td>RJ</td>\n      <td>Feminino</td>\n      <td>Parda</td>\n      <td>Não</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>154159</th>\n      <td>Medicina Veterinária</td>\n      <td>SP</td>\n      <td>Feminino</td>\n      <td>Outro</td>\n      <td>Não</td>\n      <td>26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprouni = pd.read_json(\"pure_data/prouni.json\")\n",
    "\n",
    "adicionalprouni = pd.DataFrame({\n",
    "    'curso': addprouni['NOME_CURSO_BOLSA'],\n",
    "    'estado': addprouni['SIGLA_UF_BENEFICIARIO_BOLSA'],\n",
    "    'sexo': addprouni['SEXO_BENEFICIARIO_BOLSA'].map(lambda sexo: 'Masculino' if sexo == 'M' else 'Feminino'),\n",
    "    'raca': addprouni['RACA_BENEFICIARIO_BOLSA'].map(lambda raca: 'Outro' if raca not in ['Parda', 'Branca', 'Preta'] else raca),\n",
    "    'deficiente': addprouni['BENEFICIARIO_DEFICIENTE_FISICO'].map(lambda deficiente: 'Sim' if deficiente == 'S' else 'Não'),\n",
    "    'idade': addprouni['DT_NASCIMENTO_BENEFICIARIO'].map(procdata.get_age_from_birthdate)\n",
    "})\n",
    "#addprouni.head(3)\n",
    "print(adicionalprouni.__len__(), \"rows\")\n",
    "adicionalprouni.sample(n=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/4r9_jk_s59n2616g7y9snmn00000gn/T/ipykernel_27797/3757209670.py:1: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edbasica = pd.read_csv(\"pure_data/microdados_ed_basica_2021.csv\", sep=\";\", encoding=\"latin-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221140 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": "       estado esgoto_inexistente energia_inexistente agua_inexistente  \\\n208151     RS                Não                 Não              Não   \n55220      CE                Não                 Não              Não   \n167832     SP                Não                 Não              Não   \n200114     RS                Não                 Não              Não   \n165015     SP                Não                 Não              Não   \n88265      BA                Não                 Não              Não   \n201356     RS                Não                 Não              Não   \n41112      PI                Não                 Não              Não   \n36343      MA                Não                 Não              Não   \n160993     SP                Não                 Não              Não   \n\n       acesso_internet faz_exame_selecao especializada_deficientes  \\\n208151             Sim               Não                       Não   \n55220              Sim               Não                       Sim   \n167832             Sim               Não                       Sim   \n200114             Sim               Não                       Sim   \n165015             Sim               Não                       Não   \n88265              Sim               Não                       Sim   \n201356             Sim               Não                       Não   \n41112              Não               Não                       Sim   \n36343              Não               Não                       Não   \n160993             Não               Não                       Não   \n\n       ensino_tecnico  \n208151            Não  \n55220             Não  \n167832            Não  \n200114            Não  \n165015            Não  \n88265             Não  \n201356            Não  \n41112             Não  \n36343             Não  \n160993            Não  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>estado</th>\n      <th>esgoto_inexistente</th>\n      <th>energia_inexistente</th>\n      <th>agua_inexistente</th>\n      <th>acesso_internet</th>\n      <th>faz_exame_selecao</th>\n      <th>especializada_deficientes</th>\n      <th>ensino_tecnico</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>208151</th>\n      <td>RS</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n    </tr>\n    <tr>\n      <th>55220</th>\n      <td>CE</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n    </tr>\n    <tr>\n      <th>167832</th>\n      <td>SP</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n    </tr>\n    <tr>\n      <th>200114</th>\n      <td>RS</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n    </tr>\n    <tr>\n      <th>165015</th>\n      <td>SP</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n    </tr>\n    <tr>\n      <th>88265</th>\n      <td>BA</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n    </tr>\n    <tr>\n      <th>201356</th>\n      <td>RS</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n    </tr>\n    <tr>\n      <th>41112</th>\n      <td>PI</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Sim</td>\n      <td>Não</td>\n    </tr>\n    <tr>\n      <th>36343</th>\n      <td>MA</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n    </tr>\n    <tr>\n      <th>160993</th>\n      <td>SP</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n      <td>Não</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edbasica = pd.read_csv(\"pure_data/microdados_ed_basica_2021.csv\", sep=\";\", encoding=\"latin-1\")\n",
    "\n",
    "educacaobasica = pd.DataFrame({\n",
    "    'estado': edbasica['SG_UF'],\n",
    "    'esgoto_inexistente': edbasica['IN_ESGOTO_INEXISTENTE'].map(procdata.get_label_from_floatbool),\n",
    "    'energia_inexistente': edbasica['IN_ENERGIA_INEXISTENTE'].map(procdata.get_label_from_floatbool),\n",
    "    'agua_inexistente': edbasica['IN_AGUA_INEXISTENTE'].map(procdata.get_label_from_floatbool),\n",
    "    'acesso_internet': edbasica['IN_INTERNET'].map(procdata.get_label_from_floatbool),\n",
    "    'faz_exame_selecao': edbasica['IN_EXAME_SELECAO'].map(procdata.get_label_from_floatbool),\n",
    "    'especializada_deficientes': edbasica['IN_ESP'].map(procdata.get_label_from_floatbool),\n",
    "    'ensino_tecnico': edbasica['IN_PROF_TEC'].map(procdata.get_label_from_floatbool)\n",
    "})\n",
    "#dfedbasica = spark.createDataFrame(geralprouni)\n",
    "#edbasica.head(10)\n",
    "print(educacaobasica.__len__(), \"rows\")\n",
    "educacaobasica.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [79]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m arr \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(np\u001B[38;5;241m.\u001B[39mzeros((prouni\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__len__\u001B[39m(), prouni\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__len__\u001B[39m())))\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m#print(arr[1].map(lambda x: x+1))\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mprouni\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43madicionalprouni\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_index\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mestado\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mestado\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(df\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m10\u001B[39m))\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m#spark.createDataFrame(prouni).rdd\\\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m#    .map(lambda c: adicionalprouni[(adicionalprouni['estado']==c['estado'])].sample()['sexo'])\\\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m#    .foreach(lambda x: print(x))\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m#df['sexo'] = prouni['estado'].map(lambda curso: adicionalprouni[(adicionalprouni['estado']==curso)].sample()['sexo'])\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m#print(df['sexo'])\u001B[39;00m\n",
      "File \u001B[0;32m~/GITHUB/grupo-g2-pi-2022/PYSPARK-SPRINT-3/env/lib/python3.10/site-packages/pandas/core/frame.py:9254\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001B[0m\n\u001B[1;32m   9100\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mjoin\u001B[39m(\n\u001B[1;32m   9101\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   9102\u001B[0m     other: DataFrame \u001B[38;5;241m|\u001B[39m Series,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   9107\u001B[0m     sort: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   9108\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[1;32m   9109\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   9110\u001B[0m \u001B[38;5;124;03m    Join columns of another DataFrame.\u001B[39;00m\n\u001B[1;32m   9111\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   9252\u001B[0m \u001B[38;5;124;03m    5  K1  A5   B1\u001B[39;00m\n\u001B[1;32m   9253\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 9254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_join_compat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   9255\u001B[0m \u001B[43m        \u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlsuffix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlsuffix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrsuffix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrsuffix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\n\u001B[1;32m   9256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/GITHUB/grupo-g2-pi-2022/PYSPARK-SPRINT-3/env/lib/python3.10/site-packages/pandas/core/frame.py:9285\u001B[0m, in \u001B[0;36mDataFrame._join_compat\u001B[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001B[0m\n\u001B[1;32m   9276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m how \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcross\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   9277\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m merge(\n\u001B[1;32m   9278\u001B[0m             \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   9279\u001B[0m             other,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   9283\u001B[0m             sort\u001B[38;5;241m=\u001B[39msort,\n\u001B[1;32m   9284\u001B[0m         )\n\u001B[0;32m-> 9285\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmerge\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   9286\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9287\u001B[0m \u001B[43m        \u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9288\u001B[0m \u001B[43m        \u001B[49m\u001B[43mleft_on\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9289\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhow\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9290\u001B[0m \u001B[43m        \u001B[49m\u001B[43mleft_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   9291\u001B[0m \u001B[43m        \u001B[49m\u001B[43mright_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   9292\u001B[0m \u001B[43m        \u001B[49m\u001B[43msuffixes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlsuffix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrsuffix\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9293\u001B[0m \u001B[43m        \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9294\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   9295\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   9296\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m on \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/GITHUB/grupo-g2-pi-2022/PYSPARK-SPRINT-3/env/lib/python3.10/site-packages/pandas/core/reshape/merge.py:122\u001B[0m, in \u001B[0;36mmerge\u001B[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;129m@Substitution\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mleft : DataFrame or named Series\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     91\u001B[0m \u001B[38;5;129m@Appender\u001B[39m(_merge_doc, indents\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmerge\u001B[39m(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    105\u001B[0m     validate: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    106\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[1;32m    107\u001B[0m     op \u001B[38;5;241m=\u001B[39m _MergeOperation(\n\u001B[1;32m    108\u001B[0m         left,\n\u001B[1;32m    109\u001B[0m         right,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    120\u001B[0m         validate\u001B[38;5;241m=\u001B[39mvalidate,\n\u001B[1;32m    121\u001B[0m     )\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/GITHUB/grupo-g2-pi-2022/PYSPARK-SPRINT-3/env/lib/python3.10/site-packages/pandas/core/reshape/merge.py:716\u001B[0m, in \u001B[0;36m_MergeOperation.get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindicator:\n\u001B[1;32m    714\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleft, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indicator_pre_merge(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleft, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright)\n\u001B[0;32m--> 716\u001B[0m join_index, left_indexer, right_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_join_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    718\u001B[0m llabels, rlabels \u001B[38;5;241m=\u001B[39m _items_overlap_with_suffix(\n\u001B[1;32m    719\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleft\u001B[38;5;241m.\u001B[39m_info_axis, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright\u001B[38;5;241m.\u001B[39m_info_axis, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msuffixes\n\u001B[1;32m    720\u001B[0m )\n\u001B[1;32m    722\u001B[0m lindexers \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m1\u001B[39m: left_indexer} \u001B[38;5;28;01mif\u001B[39;00m left_indexer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}\n",
      "File \u001B[0;32m~/GITHUB/grupo-g2-pi-2022/PYSPARK-SPRINT-3/env/lib/python3.10/site-packages/pandas/core/reshape/merge.py:958\u001B[0m, in \u001B[0;36m_MergeOperation._get_join_info\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    953\u001B[0m     join_index, left_indexer, right_indexer \u001B[38;5;241m=\u001B[39m left_ax\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m    954\u001B[0m         right_ax, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhow, return_indexers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, sort\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msort\n\u001B[1;32m    955\u001B[0m     )\n\u001B[1;32m    957\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright_index \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhow \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 958\u001B[0m     join_index, left_indexer, right_indexer \u001B[38;5;241m=\u001B[39m \u001B[43m_left_join_on_index\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    959\u001B[0m \u001B[43m        \u001B[49m\u001B[43mleft_ax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright_ax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mleft_join_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort\u001B[49m\n\u001B[1;32m    960\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    962\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleft_index \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhow \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mright\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    963\u001B[0m     join_index, right_indexer, left_indexer \u001B[38;5;241m=\u001B[39m _left_join_on_index(\n\u001B[1;32m    964\u001B[0m         right_ax, left_ax, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright_join_keys, sort\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msort\n\u001B[1;32m    965\u001B[0m     )\n",
      "File \u001B[0;32m~/GITHUB/grupo-g2-pi-2022/PYSPARK-SPRINT-3/env/lib/python3.10/site-packages/pandas/core/reshape/merge.py:2061\u001B[0m, in \u001B[0;36m_left_join_on_index\u001B[0;34m(left_ax, right_ax, join_keys, sort)\u001B[0m\n\u001B[1;32m   2058\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2059\u001B[0m     jkey \u001B[38;5;241m=\u001B[39m join_keys[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m-> 2061\u001B[0m     left_indexer, right_indexer \u001B[38;5;241m=\u001B[39m \u001B[43m_get_single_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright_ax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2063\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sort \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(left_ax) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(left_indexer):\n\u001B[1;32m   2064\u001B[0m     \u001B[38;5;66;03m# if asked to sort or there are 1-to-many matches\u001B[39;00m\n\u001B[1;32m   2065\u001B[0m     join_index \u001B[38;5;241m=\u001B[39m left_ax\u001B[38;5;241m.\u001B[39mtake(left_indexer)\n",
      "File \u001B[0;32m~/GITHUB/grupo-g2-pi-2022/PYSPARK-SPRINT-3/env/lib/python3.10/site-packages/pandas/core/reshape/merge.py:2039\u001B[0m, in \u001B[0;36m_get_single_indexer\u001B[0;34m(join_key, index, sort)\u001B[0m\n\u001B[1;32m   2034\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_single_indexer\u001B[39m(\n\u001B[1;32m   2035\u001B[0m     join_key, index: Index, sort: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   2036\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[npt\u001B[38;5;241m.\u001B[39mNDArray[np\u001B[38;5;241m.\u001B[39mintp], npt\u001B[38;5;241m.\u001B[39mNDArray[np\u001B[38;5;241m.\u001B[39mintp]]:\n\u001B[1;32m   2037\u001B[0m     left_key, right_key, count \u001B[38;5;241m=\u001B[39m _factorize_keys(join_key, index\u001B[38;5;241m.\u001B[39m_values, sort\u001B[38;5;241m=\u001B[39msort)\n\u001B[0;32m-> 2039\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlibjoin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mleft_outer_join\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft_key\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright_key\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcount\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32mpandas/_libs/join.pyx:139\u001B[0m, in \u001B[0;36mpandas._libs.join.left_outer_join\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/algos.pyx:241\u001B[0m, in \u001B[0;36mpandas._libs.algos.groupsort_indexer\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mstringsource:1044\u001B[0m, in \u001B[0;36mView.MemoryView.memoryview_fromslice\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# prouni\n",
    "# adicionalprouni\n",
    "# educacaobasica\n",
    "\n",
    "aditional = []\n",
    "educacaoaditional = []\n",
    "\n",
    "#pd.Series(np.arange(prouni.__len__())).map(lambda _: )\n",
    "arr = pd.DataFrame(np.zeros((prouni.__len__(), prouni.columns.__len__())))\n",
    "#print(arr[1].map(lambda x: x+1))\n",
    "\n",
    "df = prouni.join(adicionalprouni.set_index('estado'), on='estado')\n",
    "print(df.head(10))\n",
    "#spark.createDataFrame(prouni).rdd\\\n",
    "#    .map(lambda c: adicionalprouni[(adicionalprouni['estado']==c['estado'])].sample()['sexo'])\\\n",
    "#    .foreach(lambda x: print(x))\n",
    "\n",
    "#rdd2 = rdd.map(lambda c: )\n",
    "#rdd2.collect()\n",
    "#df = spark.createDataFrame(prouni)\n",
    "#df.\n",
    "#df['estado'].map(lambda curso: adicionalprouni[(adicionalprouni['estado']==curso)].sample()['sexo'])\n",
    "#df = prouni.copy()\n",
    "#df['sexo'] = prouni['estado'].map(lambda curso: adicionalprouni[(adicionalprouni['estado']==curso)].sample()['sexo'])\n",
    "#print(df['sexo'])\n",
    "\"\"\"\n",
    "prouni.reset_index()\n",
    "for row in prouni.itertuples():\n",
    "\n",
    "    prouni_adicional = adicionalprouni[(adicionalprouni['curso']==row.curso) & (adicionalprouni['estado']==row.estado)]\n",
    "    educacao_adicional = educacaobasica[(educacaobasica['estado']==row.estado)]\n",
    "\n",
    "    aditional.append(prouni_adicional.sample() if len(prouni_adicional) > 0 else adicionalprouni.sample())\n",
    "    educacaoaditional.append(educacao_adicional.sample() if len(educacao_adicional) > 0 else educacaobasica.sample())\n",
    "\n",
    "aditional\n",
    "educacaoaditional\n",
    "#pd.DataFrame(educacaoaditional)\n",
    "\n",
    "newdf = pd.concat(aditional)\n",
    "df2 = prouni.assign(ad = pd.Series(newdf['sexo']))\n",
    "df2\n",
    "newdf['sexo']\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# dateparsed = datetime.strptime(date[:-5], \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprouni = pd.read_json(\"pure_data/prouni.json\")\n",
    "\n",
    "adicionalprouni = pd.DataFrame({\n",
    "    'curso': addprouni['NOME_CURSO_BOLSA'],\n",
    "    'estado': addprouni['SIGLA_UF_BENEFICIARIO_BOLSA'],\n",
    "    'sexo': addprouni['SEXO_BENEFICIARIO_BOLSA'].map(lambda sexo: 'Masculino' if sexo == 'M' else 'Feminino'),\n",
    "    'raca': addprouni['RACA_BENEFICIARIO_BOLSA'].map(lambda raca: 'Outro' if raca not in ['Parda', 'Branca', 'Preta'] else raca),\n",
    "    'deficiente': addprouni['BENEFICIARIO_DEFICIENTE_FISICO'].map(lambda deficiente: 'Sim' if deficiente == 'S' else 'Não'),\n",
    "    'idade': addprouni['DT_NASCIMENTO_BENEFICIARIO'].map(procdata.get_age_from_birthdate)\n",
    "})\n",
    "#addprouni.head(3)\n",
    "adicionalprouni.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12442/693207899.py:1: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edbasica = pd.read_csv(\"pure_data/microdados_ed_basica_2021.csv\", sep=\";\", encoding=\"latin-1\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estado</th>\n",
       "      <th>esgoto_inexistente</th>\n",
       "      <th>energia_inexistente</th>\n",
       "      <th>agua_inexistente</th>\n",
       "      <th>acesso_internet</th>\n",
       "      <th>faz_exame_selecao</th>\n",
       "      <th>especializada_deficientes</th>\n",
       "      <th>ensino_tecnico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162696</th>\n",
       "      <td>SP</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14293</th>\n",
       "      <td>PA</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189361</th>\n",
       "      <td>PR</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129037</th>\n",
       "      <td>MG</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56514</th>\n",
       "      <td>CE</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112159</th>\n",
       "      <td>MG</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19289</th>\n",
       "      <td>PA</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59350</th>\n",
       "      <td>RN</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203715</th>\n",
       "      <td>RS</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93812</th>\n",
       "      <td>BA</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estado esgoto_inexistente energia_inexistente agua_inexistente  \\\n",
       "162696     SP                Não                 Não              Não   \n",
       "14293      PA                Não                 Não              Não   \n",
       "189361     PR                Não                 Não              Não   \n",
       "129037     MG                Não                 Não              Não   \n",
       "56514      CE                Não                 Não              Não   \n",
       "112159     MG                Não                 Não              Não   \n",
       "19289      PA                Sim                 Sim              Sim   \n",
       "59350      RN                Não                 Não              Não   \n",
       "203715     RS                Não                 Não              Não   \n",
       "93812      BA                Não                 Não              Não   \n",
       "\n",
       "       acesso_internet faz_exame_selecao especializada_deficientes  \\\n",
       "162696             Sim               Não                       Sim   \n",
       "14293              Sim               Não                       Sim   \n",
       "189361             Sim               Não                       Sim   \n",
       "129037             Não               Não                       Não   \n",
       "56514              Não               Não                       Não   \n",
       "112159             Sim               Não                       Não   \n",
       "19289              Não               Não                       Sim   \n",
       "59350              Não               Não                       Não   \n",
       "203715             Sim               Não                       Sim   \n",
       "93812              Sim               Sim                       Sim   \n",
       "\n",
       "       ensino_tecnico  \n",
       "162696            Não  \n",
       "14293             Não  \n",
       "189361            Não  \n",
       "129037            Não  \n",
       "56514             Não  \n",
       "112159            Não  \n",
       "19289             Não  \n",
       "59350             Não  \n",
       "203715            Não  \n",
       "93812             Não  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edbasica = pd.read_csv(\"pure_data/microdados_ed_basica_2021.csv\", sep=\";\", encoding=\"latin-1\")\n",
    "\n",
    "educacaobasica = pd.DataFrame({\n",
    "    'estado': edbasica['SG_UF'],\n",
    "    'esgoto_inexistente': edbasica['IN_ESGOTO_INEXISTENTE'].map(procdata.get_label_from_floatbool),\n",
    "    'energia_inexistente': edbasica['IN_ENERGIA_INEXISTENTE'].map(procdata.get_label_from_floatbool),\n",
    "    'agua_inexistente': edbasica['IN_AGUA_INEXISTENTE'].map(procdata.get_label_from_floatbool),\n",
    "    'acesso_internet': edbasica['IN_INTERNET'].map(procdata.get_label_from_floatbool),\n",
    "    'faz_exame_selecao': edbasica['IN_EXAME_SELECAO'].map(procdata.get_label_from_floatbool),\n",
    "    'especializada_deficientes': edbasica['IN_ESP'].map(procdata.get_label_from_floatbool),\n",
    "    'ensino_tecnico': edbasica['IN_PROF_TEC'].map(procdata.get_label_from_floatbool)\n",
    "})\n",
    "#dfedbasica = spark.createDataFrame(geralprouni)\n",
    "#edbasica.head(10)\n",
    "educacaobasica.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adicionalprouni[(adicionalprouni['curso']=='Enfermagem') & (adicionalprouni['estado']=='SP')].sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# dateparsed = datetime.strptime(date[:-5], \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "sm = SequenceMatcher(None, \"S@o Pa*lo\", \"São Paulo\")\n",
    "sm.ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "737ded1b7130139c98941fe8735c597799a4df27f381bdac8d9bcef9ffcf7874"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}